{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import copy\n",
    "import numpy as np\n",
    "import tqdm\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "import pytest\n",
    "\n",
    "from metadetect.lsst.metadetect import run_metadetect\n",
    "import descwl_shear_sims as sim\n",
    "\n",
    "\n",
    "CONFIG = {\n",
    "    \"meas_type\": \"wmom\",\n",
    "    \"metacal\": {\n",
    "        \"use_noise_image\": True,\n",
    "        \"psf\": \"fitgauss\",\n",
    "    },\n",
    "    \"psf\": {\n",
    "        \"model\": \"gauss\",\n",
    "        \"lm_pars\": {},\n",
    "        \"ntry\": 2,\n",
    "    },\n",
    "    \"weight\": {\n",
    "        \"fwhm\": 1.2,\n",
    "    },\n",
    "    \"detect\": {\n",
    "        \"thresh\": 10.0,\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _shear_cuts(arr):\n",
    "    assert arr is not None\n",
    "    msk = (\n",
    "        (arr['wmom_flags'] == 0)\n",
    "        & (arr['wmom_s2n'] > 10)\n",
    "        & (arr['wmom_T_ratio'] > 1.2)\n",
    "    )\n",
    "    return msk\n",
    "\n",
    "\n",
    "def _meas_shear_data(res):\n",
    "    msk = _shear_cuts(res['noshear'])\n",
    "    g1 = np.mean(res['noshear']['wmom_g'][msk, 0])\n",
    "    g2 = np.mean(res['noshear']['wmom_g'][msk, 1])\n",
    "\n",
    "    msk = _shear_cuts(res['1p'])\n",
    "    g1_1p = np.mean(res['1p']['wmom_g'][msk, 0])\n",
    "    msk = _shear_cuts(res['1m'])\n",
    "    g1_1m = np.mean(res['1m']['wmom_g'][msk, 0])\n",
    "    R11 = (g1_1p - g1_1m) / 0.02\n",
    "\n",
    "    dt = [\n",
    "        ('g1', 'f8'),\n",
    "        ('g2', 'f8'),\n",
    "        ('R11', 'f8'),\n",
    "    ]\n",
    "    return np.array([(g1, g2, R11)], dtype=dt)\n",
    "\n",
    "\n",
    "def _bootstrap_stat(d1, d2, func, seed, nboot=500):\n",
    "    dim = d1.shape[0]\n",
    "    rng = np.random.RandomState(seed=seed)\n",
    "    stats = []\n",
    "    for _ in tqdm.trange(nboot, leave=False):\n",
    "        ind = rng.choice(dim, size=dim, replace=True)\n",
    "        stats.append(func(d1[ind], d2[ind]))\n",
    "    return stats\n",
    "\n",
    "\n",
    "def _meas_m_c_cancel(pres, mres):\n",
    "    x = np.mean(pres['g1'] - mres['g1'])/2\n",
    "    y = np.mean(pres['R11'] + mres['R11'])/2\n",
    "    m = x/y/0.02 - 1\n",
    "\n",
    "    x = np.mean(pres['g2'] + mres['g2'])/2\n",
    "    y = np.mean(pres['R11'] + mres['R11'])/2\n",
    "    c = x/y\n",
    "\n",
    "    return m, c\n",
    "\n",
    "\n",
    "def _boostrap_m_c(pres, mres):\n",
    "    m, c = _meas_m_c_cancel(pres, mres)\n",
    "    bdata = _bootstrap_stat(pres, mres, _meas_m_c_cancel, 14324, nboot=500)\n",
    "    merr, cerr = np.std(bdata, axis=0)\n",
    "    return m, merr, c, cerr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "!export CATSIM_DIR=/path/to/catsim\n",
    "from xlens.simulation.simulator.base import SimulateImageHalo\n",
    "import astropy.table as astable\n",
    "import fitsio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare a halo\n",
    "src_halo = astable.Table()\n",
    "src_halo[\"index\"] = np.array([1, 2])\n",
    "src_halo[\"mass\"] = np.array([4e14, 8e14])\n",
    "src_halo[\"conc\"] = np.array([6.0, 4.0])\n",
    "src_halo[\"z_lens\"] = np.array([0.2, 0.52])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[simulation]\n",
      "root_dir    =   ./\n",
      "# image directory name\n",
      "sim_name    =   sim\n",
      "# catalog directory name\n",
      "cat_dir     =   test\n",
      "sum_dir     =   test\n",
      "\n",
      "# layout\n",
      "layout = random_disk\n",
      "# number of rotation\n",
      "nrot = 2\n",
      "# number of pixels\n",
      "coadd_dim = 500\n",
      "# buff on each side\n",
      "buff = 20\n",
      "\n",
      "rotate = False\n",
      "dither = False\n",
      "\n",
      "draw_bright = False\n",
      "star_bleeds = False\n",
      "cosmic_rays = False\n",
      "bad_columns = False\n",
      "\n",
      "psf_variation = 0.0\n",
      "stellar_density = 0.0\n",
      "survey_name = LSST\n",
      "\n",
      "band        =   r\n",
      "noise_ratio =   1.0\n",
      "psf_fwhm    =   0.8\n",
      "\n",
      "Simulating for field: 1, and halo index 2\n",
      "galsim.Moffat(beta=2.5, scale_radius=0.7076510959648599).transform(1.0,0.0,0.0,1.0)\n",
      "Simulation has galaxies: 435\n",
      "<descwl_shear_sims.psfs.dmpsfs.FixedDMPSF object at 0x7f2a752dcf50>\n",
      "<descwl_shear_sims.psfs.dmpsfs.FixedDMPSF object at 0x7f2a752dcf50>\n",
      "<descwl_shear_sims.psfs.dmpsfs.FixedDMPSF object at 0x7f2a751ff3b0>\n",
      "<descwl_shear_sims.psfs.dmpsfs.FixedDMPSF object at 0x7f2a751ff3b0>\n"
     ]
    }
   ],
   "source": [
    "simulator = SimulateImageHalo(\"/global/cfs/cdirs/des/zhou/cluster_shear/repos/xlens/examples/cluster/config.ini\")\n",
    "\n",
    "with open(\"/global/cfs/cdirs/des/zhou/cluster_shear/repos/xlens/examples/cluster/config.ini\", \"r\") as f:\n",
    "    contents = f.read()\n",
    "    print(contents)\n",
    "\n",
    "import os \n",
    "os.environ['CATSIM_DIR'] = '/global/cfs/cdirs/des/zhou/cluster_shear/data/catsim'\n",
    "\n",
    "simulator.run(ifield=1, src_halo=src_halo[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_data_list = simulator.sim_data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<descwl_shear_sims.psfs.dmpsfs.FixedDMPSF at 0x7f2a752dcf50>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_data_list[0]['band_data']['i'][0].getPsf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:07<?, ?it/s]Error.  nthreads cannot be larger than environment variable \"NUMEXPR_MAX_THREADS\" (64)Error.  nthreads cannot be larger than environment variable \"NUMEXPR_MAX_THREADS\" (64)\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/global/homes/z/zchusre/.conda/envs/xlens/lib/python3.11/site-packages/joblib/externals/loky/process_executor.py\", line 463, in _process_worker\n    r = call_item()\n        ^^^^^^^^^^^\n  File \"/global/homes/z/zchusre/.conda/envs/xlens/lib/python3.11/site-packages/joblib/externals/loky/process_executor.py\", line 291, in __call__\n    return self.fn(*self.args, **self.kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/global/homes/z/zchusre/.conda/envs/xlens/lib/python3.11/site-packages/joblib/parallel.py\", line 598, in __call__\n    return [func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/global/homes/z/zchusre/.conda/envs/xlens/lib/python3.11/site-packages/joblib/parallel.py\", line 598, in <listcomp>\n    return [func(*args, **kwargs)\n            ^^^^^^^^^^^^^^^^^^^^^\n  File \"/tmp/ipykernel_1205865/3693229693.py\", line 103, in run_sim\n  File \"/tmp/ipykernel_1205865/3693229693.py\", line 82, in _run_sim_one\n  File \"/tmp/ipykernel_1205865/3693229693.py\", line 33, in _make_lsst_sim\nAssertionError\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 205\u001b[0m\n\u001b[1;32m    201\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 205\u001b[0m     \u001b[43mtest_shear_meas\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlayout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgrid\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mntrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[14], line 149\u001b[0m, in \u001b[0;36mtest_shear_meas\u001b[0;34m(layout, ntrial)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m itr \u001b[38;5;129;01min\u001b[39;00m tqdm\u001b[38;5;241m.\u001b[39mtrange(nitr):\n\u001b[1;32m    143\u001b[0m     jobs \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    144\u001b[0m         joblib\u001b[38;5;241m.\u001b[39mdelayed(run_sim)(\n\u001b[1;32m    145\u001b[0m             seeds[loc\u001b[38;5;241m+\u001b[39mi], mdet_seeds[loc\u001b[38;5;241m+\u001b[39mi], layout\u001b[38;5;241m=\u001b[39mlayout,\n\u001b[1;32m    146\u001b[0m         )\n\u001b[1;32m    147\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(nsub)\n\u001b[1;32m    148\u001b[0m     ]\n\u001b[0;32m--> 149\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mjoblib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbackend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mloky\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjobs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m out \u001b[38;5;129;01min\u001b[39;00m outputs:\n\u001b[1;32m    152\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.conda/envs/xlens/lib/python3.11/site-packages/joblib/parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[1;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[1;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[1;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[1;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/xlens/lib/python3.11/site-packages/joblib/parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[1;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[1;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[1;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[1;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[1;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/xlens/lib/python3.11/site-packages/joblib/parallel.py:1754\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait_retrieval():\n\u001b[1;32m   1748\u001b[0m \n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;66;03m# If the callback thread of a worker has signaled that its task\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m     \u001b[38;5;66;03m# triggered an exception, or if the retrieval loop has raised an\u001b[39;00m\n\u001b[1;32m   1751\u001b[0m     \u001b[38;5;66;03m# exception (e.g. `GeneratorExit`), exit the loop and surface the\u001b[39;00m\n\u001b[1;32m   1752\u001b[0m     \u001b[38;5;66;03m# worker traceback.\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_aborting:\n\u001b[0;32m-> 1754\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_error_fast\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1755\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m   1757\u001b[0m     \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m     \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/xlens/lib/python3.11/site-packages/joblib/parallel.py:1789\u001b[0m, in \u001b[0;36mParallel._raise_error_fast\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1785\u001b[0m \u001b[38;5;66;03m# If this error job exists, immediately raise the error by\u001b[39;00m\n\u001b[1;32m   1786\u001b[0m \u001b[38;5;66;03m# calling get_result. This job might not exists if abort has been\u001b[39;00m\n\u001b[1;32m   1787\u001b[0m \u001b[38;5;66;03m# called directly or if the generator is gc'ed.\u001b[39;00m\n\u001b[1;32m   1788\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m error_job \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1789\u001b[0m     \u001b[43merror_job\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_result\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/xlens/lib/python3.11/site-packages/joblib/parallel.py:745\u001b[0m, in \u001b[0;36mBatchCompletionCallBack.get_result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    739\u001b[0m backend \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparallel\u001b[38;5;241m.\u001b[39m_backend\n\u001b[1;32m    741\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m backend\u001b[38;5;241m.\u001b[39msupports_retrieve_callback:\n\u001b[1;32m    742\u001b[0m     \u001b[38;5;66;03m# We assume that the result has already been retrieved by the\u001b[39;00m\n\u001b[1;32m    743\u001b[0m     \u001b[38;5;66;03m# callback thread, and is stored internally. It's just waiting to\u001b[39;00m\n\u001b[1;32m    744\u001b[0m     \u001b[38;5;66;03m# be returned.\u001b[39;00m\n\u001b[0;32m--> 745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_return_or_raise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;66;03m# For other backends, the main thread needs to run the retrieval step.\u001b[39;00m\n\u001b[1;32m    748\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/.conda/envs/xlens/lib/python3.11/site-packages/joblib/parallel.py:763\u001b[0m, in \u001b[0;36mBatchCompletionCallBack._return_or_raise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    762\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m==\u001b[39m TASK_ERROR:\n\u001b[0;32m--> 763\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n\u001b[1;32m    764\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n\u001b[1;32m    765\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# def _make_lsst_sim(*, rng, g1, g2, layout):\n",
    "#     coadd_dim = 400\n",
    "#     buff = 25\n",
    "\n",
    "#     galaxy_catalog = sim.galaxies.make_galaxy_catalog(\n",
    "#         rng=rng,\n",
    "#         coadd_dim=coadd_dim,\n",
    "#         buff=buff,\n",
    "#         layout=layout,\n",
    "#         gal_type='fixed',\n",
    "#     )\n",
    "\n",
    "#     psf = sim.psfs.make_fixed_psf(psf_type='gauss')\n",
    "\n",
    "#     sim_data = sim.make_sim(\n",
    "#         rng=rng,\n",
    "#         galaxy_catalog=galaxy_catalog,\n",
    "#         coadd_dim=coadd_dim,\n",
    "#         g1=g1,\n",
    "#         g2=g2,\n",
    "#         psf=psf,\n",
    "#     )\n",
    "#     return sim_data\n",
    "\n",
    "# import pickle\n",
    "# sims_dir = \"/global/cfs/cdirs/des/zhou/cluster_shear/data/sims\"\n",
    "\n",
    "def _make_lsst_sim(index, sim_data_list):\n",
    "    # with open(os.path.join(sims_dir,\"sim_data_1_0.pkl\"), \"rb\") as f:_list[0]\n",
    "    #     res_data = pickle.load(f)_list[0]\n",
    "    #     sim_data = res_data['sim_data']_list[0]\n",
    "    #     psf = res_data['psf']_list[0]\n",
    "    assert sim_data_list[index]['band_data']['i'][0].getPsf() is not None\n",
    "    return sim_data_list[index]\n",
    "\n",
    "\n",
    "def _coadd_sim_data(rng, sim_data, nowarp, remove_poisson):\n",
    "    \"\"\"\n",
    "    copied from mdet-lsst-sim\n",
    "    \"\"\"\n",
    "    from descwl_coadd.coadd import make_coadd\n",
    "    from descwl_coadd.coadd_nowarp import make_coadd_nowarp\n",
    "    from metadetect.lsst.util import extract_multiband_coadd_data\n",
    "\n",
    "    bands = list(sim_data['band_data'].keys())\n",
    "    print(\"The bands are:\", bands)\n",
    "\n",
    "    if nowarp:\n",
    "        exps = sim_data['band_data'][bands[0]]\n",
    "\n",
    "        if len(exps) > 1:\n",
    "            raise ValueError('only one epoch for nowarp')\n",
    "\n",
    "        print(exps[0].getPsf())\n",
    "        \n",
    "        coadd_data_list = [\n",
    "            make_coadd_nowarp(\n",
    "                exp=exps[0],\n",
    "                psf_dims=sim_data['psf_dims'],\n",
    "                rng=rng,\n",
    "                remove_poisson=remove_poisson,\n",
    "            )\n",
    "            for band in bands\n",
    "        ]\n",
    "    else:\n",
    "        coadd_data_list = [\n",
    "            make_coadd(\n",
    "                exps=sim_data['band_data'][band],\n",
    "                psf_dims=sim_data['psf_dims'],\n",
    "                rng=rng,\n",
    "                coadd_wcs=sim_data['coadd_wcs'],\n",
    "                coadd_bbox=sim_data['coadd_bbox'],\n",
    "                remove_poisson=remove_poisson,\n",
    "            )\n",
    "            for band in bands\n",
    "        ]\n",
    "    return extract_multiband_coadd_data(coadd_data_list)\n",
    "\n",
    "def _run_sim_one(*, seed, mdet_seed, g1, g2, **kwargs):\n",
    "    rng = np.random.RandomState(seed=seed)\n",
    "    # sim_data = _make_lsst_sim(rng=rng, g1=g1, g2=g2, **kwargs)\n",
    "    sim_data = _make_lsst_sim(index=0, sim_data_list=sim_data_list)\n",
    "\n",
    "    print(sim_data_list)\n",
    "    print(sim_data['band_data']['i'][0].getPsf())\n",
    "\n",
    "    coadd_data = _coadd_sim_data(\n",
    "        rng=rng, sim_data=sim_data, nowarp=True, remove_poisson=False,\n",
    "    )\n",
    "\n",
    "    mdet_rng = np.random.RandomState(seed=mdet_seed)\n",
    "    results = run_metadetect(\n",
    "        rng=mdet_rng,\n",
    "        config=copy.deepcopy(CONFIG),\n",
    "        **coadd_data,\n",
    "    )\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "def run_sim(seed, mdet_seed, **kwargs):\n",
    "    # positive shear\n",
    "    _pres = _run_sim_one(\n",
    "        seed=seed, mdet_seed=mdet_seed,\n",
    "        g1=0.02,\n",
    "        g2=0.0,\n",
    "        **kwargs,\n",
    "    )\n",
    "    if _pres is None:\n",
    "        return None\n",
    "\n",
    "    # negative shear\n",
    "    _mres = _run_sim_one(\n",
    "        seed=seed, mdet_seed=mdet_seed,\n",
    "        g1=-0.02,\n",
    "        g2=0.0,\n",
    "        **kwargs,\n",
    "    )\n",
    "    if _mres is None:\n",
    "        return None\n",
    "\n",
    "    return _meas_shear_data(_pres), _meas_shear_data(_mres)\n",
    "\n",
    "\n",
    "# @pytest.mark.parametrize(\n",
    "    # 'layout,ntrial', [('grid', 10)]\n",
    "# )\n",
    "def test_shear_meas(layout, ntrial):\n",
    "    nsub = max(ntrial // 100, 10)\n",
    "    nitr = ntrial // nsub\n",
    "    rng = np.random.RandomState(seed=116)\n",
    "    seeds = rng.randint(low=1, high=2**29, size=ntrial)\n",
    "    mdet_seeds = rng.randint(low=1, high=2**29, size=ntrial)\n",
    "\n",
    "    tm0 = time.time()\n",
    "\n",
    "    print(\"\")\n",
    "\n",
    "    pres = []\n",
    "    mres = []\n",
    "    loc = 0\n",
    "    for itr in tqdm.trange(nitr):\n",
    "        jobs = [\n",
    "            joblib.delayed(run_sim)(\n",
    "                seeds[loc+i], mdet_seeds[loc+i], layout=layout,\n",
    "            )\n",
    "            for i in range(nsub)\n",
    "        ]\n",
    "        outputs = joblib.Parallel(n_jobs=2, verbose=0, backend='loky')(jobs)\n",
    "\n",
    "        for out in outputs:\n",
    "            if out is None:\n",
    "                continue\n",
    "            pres.append(out[0])\n",
    "            mres.append(out[1])\n",
    "        loc += nsub\n",
    "\n",
    "        m, merr, c, cerr = _boostrap_m_c(\n",
    "            np.concatenate(pres),\n",
    "            np.concatenate(mres),\n",
    "        )\n",
    "        print(\n",
    "            (\n",
    "                \"\\n\"\n",
    "                \"nsims: %d\\n\"\n",
    "                \"m [1e-3, 3sigma]: %s +/- %s\\n\"\n",
    "                \"c [1e-5, 3sigma]: %s +/- %s\\n\"\n",
    "                \"\\n\"\n",
    "            ) % (\n",
    "                len(pres),\n",
    "                m/1e-3,\n",
    "                3*merr/1e-3,\n",
    "                c/1e-5,\n",
    "                3*cerr/1e-5,\n",
    "            ),\n",
    "            flush=True,\n",
    "        )\n",
    "\n",
    "    total_time = time.time()-tm0\n",
    "    print(\"time per:\", total_time/ntrial, flush=True)\n",
    "\n",
    "    pres = np.concatenate(pres)\n",
    "    mres = np.concatenate(mres)\n",
    "    m, merr, c, cerr = _boostrap_m_c(pres, mres)\n",
    "\n",
    "    print(\n",
    "        (\n",
    "            \"\\n\\nm [1e-3, 3sigma]: %s +/- %s\"\n",
    "            \"\\nc [1e-5, 3sigma]: %s +/- %s\"\n",
    "        ) % (\n",
    "            m/1e-3,\n",
    "            3*merr/1e-3,\n",
    "            c/1e-5,\n",
    "            3*cerr/1e-5,\n",
    "        ),\n",
    "        flush=True,\n",
    "    )\n",
    "\n",
    "    assert np.abs(m) < max(1e-3, 3*merr)\n",
    "    assert np.abs(c) < 3*cerr\n",
    "    return\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test_shear_meas(layout=\"grid\", ntrial=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
